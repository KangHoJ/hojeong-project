{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFvU7ZqcUaAXr5fS+ACmdS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Weeu2GUjcub","executionInfo":{"status":"ok","timestamp":1681438708286,"user_tz":-540,"elapsed":20361,"user":{"displayName":"강호정","userId":"03873201153560303630"}},"outputId":"84a2202a-a529-4964-b059-a90e59fbb77c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/data\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/data') # 드라이브 연결"]},{"cell_type":"code","source":["%matplotlib inline\n","import torch\n","\n","x = torch.ones(5) #input\n","y = torch.zeros(3) #output\n","\n","w = torch.randn(5, 3, requires_grad=True) # weight \n","b = torch.randn(3, requires_grad=True) # bias\n","\n","z = torch.matmul(x,w)+b #wx+b\n","\n","loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y) # 예측값(z) , 실제값(y) 차이"],"metadata":{"id":"BzHjgbtIjism","executionInfo":{"status":"ok","timestamp":1681439154598,"user_tz":-540,"elapsed":5838,"user":{"displayName":"강호정","userId":"03873201153560303630"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQloHYTmn6Uj","executionInfo":{"status":"ok","timestamp":1681439859445,"user_tz":-540,"elapsed":266,"user":{"displayName":"강호정","userId":"03873201153560303630"}},"outputId":"8f3f80c7-ac72-457a-9119-b0a971f8e893"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.7577, -2.5064,  1.8667], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["print('Gradient function for z =',z.grad_fn) # 경사하강법\n","print('Gradient function for loss',loss.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Hg4NifykoWG","executionInfo":{"status":"ok","timestamp":1681439158082,"user_tz":-540,"elapsed":7,"user":{"displayName":"강호정","userId":"03873201153560303630"}},"outputId":"eafc47f8-f4be-481c-abc7-0ddc4cd69293"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient function for z = <AddBackward0 object at 0x7fbff3538be0>\n","Gradient function for loss <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fbff35389a0>\n"]}]},{"cell_type":"markdown","source":["## computing gradients"],"metadata":{"id":"EoCI60Zglpr9"}},{"cell_type":"code","source":["loss.backward() # 업데이트(학습 이후에 항상 해야함)\n","print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnE1EuXJkoZr","executionInfo":{"status":"ok","timestamp":1681439447094,"user_tz":-540,"elapsed":6,"user":{"displayName":"강호정","userId":"03873201153560303630"}},"outputId":"40aea12d-c935-4002-92f2-b5c7b289381f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2843, 0.0251, 0.2887],\n","        [0.2843, 0.0251, 0.2887],\n","        [0.2843, 0.0251, 0.2887],\n","        [0.2843, 0.0251, 0.2887],\n","        [0.2843, 0.0251, 0.2887]])\n","tensor([0.2843, 0.0251, 0.2887])\n"]}]},{"cell_type":"code","source":["z = torch.matmul(x, w)+b # 학습 구현 (train)\n","print(z.requires_grad)\n","\n","with torch.no_grad(): # 실험하는 데이터 구현 (test)\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"],"metadata":{"id":"eWen_7_Dkocq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OIJahRyukofp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mHkUsEF8koiW"},"execution_count":null,"outputs":[]}]}